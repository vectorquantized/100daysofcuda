## Day 31
Please refer to the (Loading Q, K, V Blocks in Shared Memory](https://github.com/vectorquantized/100daysofcuda/blob/main/src/flash_attention/flash_attention_kernel.md#load-the-q-k-v-blocks-in-shared-memory)
