{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import triton\n",
    "import triton.language as tl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from triton.runtime import driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(f'cuda:{torch.cuda.current_device()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = driver.active.utils.get_device_properties(DEVICE.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_shared_mem': 101376,\n",
       " 'max_num_regs': 65536,\n",
       " 'multiprocessor_count': 64,\n",
       " 'warpSize': 32,\n",
       " 'sm_clock_rate': 1695000,\n",
       " 'mem_clock_rate': 8001000,\n",
       " 'mem_bus_width': 384}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def conv2d_kernel(input_ptr: torch.Tensor, kernel_ptr: torch.Tensor, output: torch.Tensor, \n",
    "           height: int, width: int,  stride: int, kH: int, kW: int, max_kH: tl.constexpr, max_kW: tl.constexpr, BLOCK_SIZE: tl.constexpr): \n",
    "    \n",
    "    tile_row = tl.program_id(0)\n",
    "    tile_col = tl.program_id(1)\n",
    "    \n",
    "    out_height = (height - kH) // stride + 1\n",
    "    out_width = (width - kW) // stride + 1\n",
    "    \n",
    "    OUT_TILE_HEIGHT = BLOCK_SIZE - kH + 1\n",
    "    OUT_TILE_WIDTH = BLOCK_SIZE - kW + 1\n",
    "    \n",
    "    out_tile_row = tile_row * OUT_TILE_HEIGHT\n",
    "    out_tile_col = tile_col * OUT_TILE_WIDTH\n",
    "    \n",
    "    kernel_row_offset = tl.arange(0, max_kH)\n",
    "    \n",
    "    kernel_col_offset = tl.arange(0, max_kW)\n",
    "\n",
    "    # Create a mask for valid kernel indices.\n",
    "    kernel_mask = (kernel_row_offset[:, None] < kH) & (kernel_col_offset[None, :] < kW)\n",
    "    # Load a full kernel block using masked load.\n",
    "    kernel_block = tl.load(\n",
    "        kernel_ptr + kernel_row_offset[:, None] * kW + kernel_col_offset[None, :],\n",
    "        mask=kernel_mask, other=0.0\n",
    "    )\n",
    "    \n",
    "    \n",
    "    for i in tl.range(0, OUT_TILE_HEIGHT):\n",
    "        for j in tl.range(0, OUT_TILE_WIDTH):\n",
    "            # acc = 0.0\n",
    "            out_row = out_tile_row + i\n",
    "            out_col = out_tile_col + j\n",
    "            if out_row < out_height and out_col < out_width:\n",
    "                input_row = out_row * stride\n",
    "                input_col = out_col * stride\n",
    "                \n",
    "                patch_ptr = input_ptr + input_row * width + input_col\n",
    "                input_patch = patch_ptr + kernel_row_offset[:, None] * width + kernel_col_offset[None, :]\n",
    "                mask = (input_row + kernel_row_offset[:, None] < height) & (input_col + kernel_col_offset[None, :] < width) & kernel_mask\n",
    "                input_block = tl.load(input_patch, mask = mask, other=0.0)\n",
    "                acc = tl.sum(input_block * kernel_block)\n",
    "                tl.store(output + out_row * out_width + out_col, acc)\n",
    "                \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dimensions and hyperparameters.\n",
    "height, width = 512, 512     # Input dimensions.\n",
    "kH, kW = 3, 3                # Kernel dimensions.\n",
    "stride = 1\n",
    "BLOCK_SIZE = 16              # Choose a BLOCK_SIZE such that BLOCK_SIZE > kH and BLOCK_SIZE > kW.\n",
    "\n",
    "# Create dummy tensors.\n",
    "input_tensor = torch.randn(height, width, device='cuda', dtype=torch.float32)\n",
    "kernel_tensor = torch.randn(kH, kW, device='cuda', dtype=torch.float32)\n",
    "out_height = (height - kH) // stride + 1\n",
    "out_width = (width - kW) // stride + 1\n",
    "output_tensor = torch.empty(out_height, out_width, device='cuda', dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute grid dimensions based on tile size.\n",
    "OUT_TILE_HEIGHT = BLOCK_SIZE - kH + 1\n",
    "OUT_TILE_WIDTH  = BLOCK_SIZE - kW + 1\n",
    "num_tile_rows = (out_height + OUT_TILE_HEIGHT - 1) // OUT_TILE_HEIGHT\n",
    "num_tile_cols = (out_width + OUT_TILE_WIDTH - 1) // OUT_TILE_WIDTH\n",
    "\n",
    "# The grid is 2D.\n",
    "grid = (num_tile_rows, num_tile_cols)\n",
    "max_kH, max_kW = triton.next_power_of_2(kH), triton.next_power_of_2(kW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d_kernel[grid](input_tensor, kernel_tensor, output_tensor,\n",
    "    height, width, stride, kH, kW, max_kH, max_kW, BLOCK_SIZE)\n",
    "\n",
    "torch_output = F.conv2d(input_tensor[None, None, :, :], kernel_tensor[None, None, :, :]).squeeze()\n",
    "torch.allclose(output_tensor, torch_output, rtol=1e-5, atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.0729,  2.0847, -2.1746,  ..., -3.2092,  2.9327, -0.4276],\n",
       "        [ 0.6600,  1.2153, -6.4636,  ..., -1.2946,  3.0366, -7.5930],\n",
       "        [-0.2889, -1.5446, -0.2909,  ...,  3.0190,  2.6954, -3.4862],\n",
       "        ...,\n",
       "        [ 3.8405,  0.9267, -3.0867,  ..., -5.4856,  2.1411,  3.7709],\n",
       "        [ 1.4122, -2.3527, -3.4199,  ..., -0.9416, -2.9081,  2.3585],\n",
       "        [ 1.0550, -0.7478,  1.3724,  ...,  0.2417, -6.5702,  3.9521]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.0729,  2.0847, -2.1746,  ..., -3.2092,  2.9327, -0.4276],\n",
       "        [ 0.6600,  1.2153, -6.4636,  ..., -1.2946,  3.0366, -7.5930],\n",
       "        [-0.2889, -1.5446, -0.2909,  ...,  3.0190,  2.6954, -3.4862],\n",
       "        ...,\n",
       "        [ 3.8405,  0.9267, -3.0867,  ..., -5.4856,  2.1411,  3.7709],\n",
       "        [ 1.4122, -2.3527, -3.4199,  ..., -0.9416, -2.9081,  2.3585],\n",
       "        [ 1.0550, -0.7478,  1.3724,  ...,  0.2417, -6.5702,  3.9521]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch at position (0, 0):\n",
      "  Your output: -5.0729498863220215\n",
      "  PyTorch output: -5.072949409484863\n",
      "  Difference: -4.76837158203125e-07\n",
      "Mismatch at position (0, 2):\n",
      "  Your output: -2.1745619773864746\n",
      "  PyTorch output: -2.1745622158050537\n",
      "  Difference: 2.384185791015625e-07\n",
      "Mismatch at position (0, 3):\n",
      "  Your output: -0.8066891431808472\n",
      "  PyTorch output: -0.8066893815994263\n",
      "  Difference: 2.384185791015625e-07\n",
      "Mismatch at position (0, 4):\n",
      "  Your output: 6.893205642700195\n",
      "  PyTorch output: 6.8932061195373535\n",
      "  Difference: -4.76837158203125e-07\n",
      "Mismatch at position (0, 5):\n",
      "  Your output: 0.8722105026245117\n",
      "  PyTorch output: 0.8722104430198669\n",
      "  Difference: 5.960464477539063e-08\n",
      "Mismatch at position (0, 6):\n",
      "  Your output: -3.0692574977874756\n",
      "  PyTorch output: -3.0692572593688965\n",
      "  Difference: -2.384185791015625e-07\n",
      "Mismatch at position (0, 7):\n",
      "  Your output: 1.5042240619659424\n",
      "  PyTorch output: 1.5042235851287842\n",
      "  Difference: 4.76837158203125e-07\n",
      "Mismatch at position (0, 8):\n",
      "  Your output: -0.6727638244628906\n",
      "  PyTorch output: -0.6727635264396667\n",
      "  Difference: -2.980232238769531e-07\n",
      "Mismatch at position (0, 9):\n",
      "  Your output: -1.6510794162750244\n",
      "  PyTorch output: -1.6510791778564453\n",
      "  Difference: -2.384185791015625e-07\n",
      "Mismatch at position (0, 10):\n",
      "  Your output: 1.77859628200531\n",
      "  PyTorch output: 1.7785964012145996\n",
      "  Difference: -1.1920928955078125e-07\n"
     ]
    }
   ],
   "source": [
    "mismatch_indices = torch.where(output_tensor != torch_output)\n",
    "\n",
    "# Print some of the mismatches to analyze the pattern\n",
    "for i in range(min(10, len(mismatch_indices[0]))):\n",
    "    row, col = mismatch_indices[0][i], mismatch_indices[1][i]\n",
    "    print(f\"Mismatch at position ({row}, {col}):\")\n",
    "    print(f\"  Your output: {output_tensor[row, col]}\")\n",
    "    print(f\"  PyTorch output: {torch_output[row, col]}\")\n",
    "    print(f\"  Difference: {output_tensor[row, col] - torch_output[row, col]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
